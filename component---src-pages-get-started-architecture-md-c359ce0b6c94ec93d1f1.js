(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{961:function(e,t,n){"use strict";n.r(t),n.d(t,"_frontmatter",(function(){return i})),n.d(t,"default",(function(){return l}));n(11),n(6),n(5),n(3),n(7),n(4),n(8),n(1);var r=n(78),a=n(959);function o(){return(o=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(e[r]=n[r])}return e}).apply(this,arguments)}var i={};void 0!==i&&i&&i===Object(i)&&Object.isExtensible(i)&&Object.defineProperty(i,"__filemeta",{configurable:!0,value:{name:"_frontmatter",filename:"src/pages/Get_started/Architecture.md"}});var s={_frontmatter:i},c=a.a;function l(e){var t=e.components,n=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,["components"]);return Object(r.b)(c,o({},s,n,{components:t,mdxType:"MDXLayout"}),Object(r.b)("h1",{id:"spark-fhir-server"},"Spark FHIR server"),Object(r.b)("p",null,"Spark is built in three layers:"),Object(r.b)("ol",null,Object(r.b)("li",{parentName:"ol"},"Spark Server (Spark.Web for Asp.net core 2.1, or Spark.csproj for ASP.net 4.6): An ASP.Net MVC application hosting both a (minimal) visual interface, the FHIR (REST) endpoint and a Maintenance operation."),Object(r.b)("li",{parentName:"ol"},"Spark Engine (Spark.Engine.csproj): The implementation of everything FHIR: the REST interface, indexing of the search parameters and interpreting search requests, construction of FHIR responses etc."),Object(r.b)("li",{parentName:"ol"},"Spark Mongo (Spark.Mongo.csproj): Storage and retrieval of both resources and the index based on MongoDB.")),Object(r.b)("h1",{id:"spark-is-built-on-the-net-fhir-api"},"Spark is built on the .NET FHIR API"),Object(r.b)("p",null,"Spark uses the .NET FHIR API to parse and serialize resources, and as a source of metadata about the FHIR specification: what Resource types are available, what is the definition of the SearchParameters and so on. The parsing and serialization in this API is heavily optimized. Using Spark you get the benefits of that. It also means that Spark is bound to a specific version of the API, which is currently the DSTU2 version."),Object(r.b)("h1",{id:"spark-engine"},"Spark Engine"),Object(r.b)("p",null,"Spark Engine provides:"),Object(r.b)("ol",null,Object(r.b)("li",{parentName:"ol"},"Interfaces for the various functions that must be implemented by the storage layer: ",Object(r.b)("ul",{parentName:"li"},Object(r.b)("li",{parentName:"ul"},"IFhirStore: Add and retrieve resources."),Object(r.b)("li",{parentName:"ul"},"IFhirIndex: Process resources to index entries, search resources using the index."),Object(r.b)("li",{parentName:"ul"},"IIndexStore: Save and delete index entries."),Object(r.b)("li",{parentName:"ul"},"ISnapShotStore: Save and retrieve snapshots of search results for paging."),Object(r.b)("li",{parentName:"ul"},"IHistoryStore: Get previous versions of a resource, a resource type or the whole system."),Object(r.b)("li",{parentName:"ul"},"IGenerator: Generate ID's for new resources and new versions of resources."))),Object(r.b)("li",{parentName:"ol"},"Services for handling generic FHIR functionality",Object(r.b)("ul",{parentName:"li"},Object(r.b)("li",{parentName:"ul"},"SearchService: Combine IFhirIndex and ISnapShotStore to paging results."),Object(r.b)("li",{parentName:"ul"},"ElementIndexer: Translate FHIR DataTypes to parts of an Index entry."),Object(r.b)("li",{parentName:"ul"},"ConformanceService: Provide the conformance statement of Spark."))),Object(r.b)("li",{parentName:"ol"},"ASP.NET Filters for handling cross cutting FHIR concerns:",Object(r.b)("ul",{parentName:"li"},Object(r.b)("li",{parentName:"ul"},"Translating Exceptions to FHIR Response Messages (an http error or OperationOutcome)"),Object(r.b)("li",{parentName:"ul"},"(De)compression of request and response data."))),Object(r.b)("li",{parentName:"ol"},"ASP.NET Formatters for several wire formats:",Object(r.b)("ul",{parentName:"li"},Object(r.b)("li",{parentName:"ul"},"JSON"),Object(r.b)("li",{parentName:"ul"},"XML"),Object(r.b)("li",{parentName:"ul"},"Binary"),Object(r.b)("li",{parentName:"ul"},"HTML"))),Object(r.b)("li",{parentName:"ol"},"All kinds of model and helper classes to assist in the functions above.")),Object(r.b)("p",null,"This all accumulates in (I)FhirService, that presents all the FHIR functions."),Object(r.b)("h1",{id:"spark-mongo"},"Spark Mongo"),Object(r.b)("p",null,"The MongoDB implementation of Spark stores the resources, the index, the snapshots and the generated ID's in MongoDB, with one collection for each. Previous versions of resources are also in the Resources collection. The Index collection contains only the current version of every resource."),Object(r.b)("p",null,"MongoSearcher implements the actual searching mechanism on the MongoDB index, using the generic ResourceVisitor and Criterium classes in Spark Engine."),Object(r.b)("p",null,"Be aware that MongoDB is heavily used (especially on searches), so it should be on an endpoint with very little latency."))}l&&l===Object(l)&&Object.isExtensible(l)&&Object.defineProperty(l,"__filemeta",{configurable:!0,value:{name:"MDXContent",filename:"src/pages/Get_started/Architecture.md"}}),l.isMDXComponent=!0}}]);
//# sourceMappingURL=component---src-pages-get-started-architecture-md-c359ce0b6c94ec93d1f1.js.map