{"version":3,"sources":["webpack:///./src/pages/Get_started/Run_with_Docker.md"],"names":["_frontmatter","layoutProps","MDXLayout","DefaultLayout","MDXContent","components","props","mdxType","parentName","isMDXComponent"],"mappings":"ocAMO,IAAMA,EAAe,Q,yLAE5B,IAKMC,EAAc,CAClBD,gBAEIE,EAAYC,IACH,SAASC,EAAT,GAGZ,IAFDC,EAEC,EAFDA,WACGC,E,oIACF,mBACD,OAAO,YAACJ,EAAD,KAAeD,EAAiBK,EAAhC,CAAuCD,WAAYA,EAAYE,QAAQ,cAG5E,iBAAQ,CACN,GAAM,2BADR,2BAGA,kGACA,uBAAK,sBAAMC,WAAW,OAAU,IAA3B,kuBAwBL,qGAAoF,0BAAYA,WAAW,KAAvB,qBAApF,UACA,uBAAK,sBAAMA,WAAW,OAAU,IAA3B,gjC,gLA4CTJ,EAAWK,gBAAiB","file":"component---src-pages-get-started-run-with-docker-md-aa4eed704e7613733b15.js","sourcesContent":["import React from 'react'\n  /* @jsx mdx */\nimport { mdx } from '@mdx-js/react';\n/* @jsx mdx */\n\nimport DefaultLayout from \"/home/runner/work/spark/spark/docs/node_modules/gatsby-theme-docz/src/base/Layout.js\";\nexport const _frontmatter = {};\n\nconst makeShortcode = name => function MDXDefaultShortcode(props) {\n  console.warn(\"Component \" + name + \" was not imported, exported, or provided by MDXProvider as global scope\");\n  return <div {...props} />;\n};\n\nconst layoutProps = {\n  _frontmatter\n};\nconst MDXLayout = DefaultLayout;\nexport default function MDXContent({\n  components,\n  ...props\n}) {\n  return <MDXLayout {...layoutProps} {...props} components={components} mdxType=\"MDXLayout\">\n\n\n    <h1 {...{\n      \"id\": \"running-spark-in-docker\"\n    }}>{`Running Spark in Docker`}</h1>\n    <p>{`Spark can run in a Docker. This is a sample Dockerfile for running Spark.`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{`FROM mcr.microsoft.com/dotnet/core/aspnet:2.2-stretch-slim AS base\nWORKDIR /app\nEXPOSE 80\nEXPOSE 443\n\nFROM mcr.microsoft.com/dotnet/core/sdk:2.2-stretch AS build\nWORKDIR /src\nCOPY [\"./src/Spark.Web/\", \"Spark.Web/\"]\nCOPY [\"./src/Spark.Engine/\", \"Spark.Engine/\"]\nCOPY [\"./src/Spark.Mongo/\", \"Spark.Mongo/\"]\nRUN dotnet restore \"/src/Spark.Web/Spark.Web.csproj\"\nCOPY . .\nRUN dotnet build \"/src/Spark.Web/Spark.Web.csproj\" -c Release -o /app\n\nFROM build AS publish\nRUN dotnet publish \"/src/Spark.Web/Spark.Web.csproj\" -c Release -o /app\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app .\n# COPY --from=build /src/Spark.Web/example_data/fhir_examples ./fhir_examples\n\nENTRYPOINT [\"dotnet\", \"Spark.Web.dll\"]\n`}</code></pre>\n    <p>{`If you want to run the Mongo database as well, you could configure it with a `}<inlineCode parentName=\"p\">{`docker-compse.yml`}</inlineCode>{`-file:`}</p>\n    <pre><code parentName=\"pre\" {...{}}>{`version: \"3\"\nservices:\n  spark:\n    container_name: spark\n    restart: always\n    build:\n      context: .\n      dockerfile: Dockerfile\n    environment:\n      - StoreSettings__ConnectionString=mongodb://root:CosmicTopSecret@mongodb:27017/spark?authSource=admin\n      - SparkSettings__Endpoint=http://localhost:5555/fhir\n    ports:\n      - \"5555:80\"\n      - \"44348:443\"\n    links:\n      - mongodb\n    depends_on:\n      - mongodb\n  mongodb:\n    container_name: mongodb\n    image: mongo\n    environment:\n      MONGO_INITDB_ROOT_USERNAME: root\n      MONGO_INITDB_ROOT_PASSWORD: CosmicTopSecret\n    ports:\n      - \"17017:27017\"\n  mongosetup:\n    container_name: mongosetup\n    image: mongo\n    volumes:\n      - ./src/Spark.Web/example_data/db_dump:/data/db_dump\n    depends_on:\n      - mongodb\n    links:\n      - mongodb\n    entrypoint:\n      [\"mongorestore\", \"--uri=mongodb://root:CosmicTopSecret@mongodb:27017/spark\", \"--drop\", \"--archive=/data/db_dump/dstu2.archive.gz\", \"--gzip\"]\n    environment:\n      WAIT_HOSTS: mongodb:27017\n`}</code></pre>\n\n    </MDXLayout>;\n}\n;\nMDXContent.isMDXComponent = true;\n      "],"sourceRoot":""}